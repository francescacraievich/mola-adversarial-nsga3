{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Multi-Objective Adversarial Perturbations for SLAM Systems","text":"<p>Welcome to the documentation for the MOLA Adversarial NSGA-III project.</p>"},{"location":"#overview","title":"Overview","text":"<p>This project applies NSGA-III (Non-dominated Sorting Genetic Algorithm III) to evolve adversarial perturbations on LiDAR point clouds that can compromise SLAM (Simultaneous Localization and Mapping) systems. The project implements state-of-the-art adversarial attack techniques inspired by recent research:</p> <ul> <li>FLAT: Flux-Aware Imperceptible Adversarial Attacks (ECCV 2024)</li> <li>SLACK: Attacking LiDAR-based SLAM (arXiv 2024)</li> <li>ICP Attack: Adversarial attacks on ICP registration (arXiv 2403.05666)</li> <li>ASP: Attribution-based Scanline Perturbation (IEEE 2024)</li> </ul>"},{"location":"#objectives","title":"Objectives","text":"<p>The algorithm optimizes two competing objectives:</p> <ol> <li>Attack Effectiveness - Maximize localization error (ATE) in MOLA SLAM</li> <li>Imperceptibility - Minimize perturbation magnitude (Chamfer distance)</li> </ol> <p>This creates a Pareto front of optimal trade-offs between attack effectiveness and detectability.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>NSGA-III optimization with Das-Dennis reference directions</li> <li>17-parameter genome combining multiple attack strategies</li> <li>Advanced attacks: Edge targeting, temporal drift, scanline perturbation, geometric distortion</li> <li>Integration with MOLA SLAM in Isaac Sim</li> <li>Automated fitness evaluation using ground truth comparison</li> <li>Comprehensive analysis and visualization tools</li> </ul>"},{"location":"#attack-strategies","title":"Attack Strategies","text":"<p>The 17-parameter genome encodes:</p> Attack Type Description Effectiveness Dropout Remove random points High (18.9% ATE/cm) Gaussian noise Add random displacement Medium (15.2% ATE/cm) Edge attack Target ICP-critical features High Temporal drift Accumulating bias (breaks loop closure) Very High Geometric distortion Range-dependent scaling High Scanline perturbation Along-beam perturbation Medium Strategic ghost Feature-based ghost points Medium"},{"location":"#project-context","title":"Project Context","text":"<p>This project is part of a practical application of multi-objective evolutionary algorithms. The setup includes:</p> <ul> <li>MOLA SLAM operational in Isaac Sim</li> <li>Recorded point clouds from a simulated rover (~11.3s, 113 frames at 10Hz)</li> <li>Automatic fitness evaluation using Umeyama-aligned ATE</li> <li>Baseline ATE: ~6.8cm (unperturbed)</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation Guide</li> <li>Quick Start</li> <li>NSGA-III Algorithm Details</li> <li>Perturbation Strategies</li> <li>API Reference</li> <li>Experimental Results</li> </ul>"},{"location":"#repository","title":"Repository","text":"<p>View the source code on GitHub.</p>"},{"location":"api/overview/","title":"API Reference","text":""},{"location":"api/overview/#overview","title":"Overview","text":"<p>This document provides an API reference for the main modules in the MOLA Adversarial NSGA-II project.</p>"},{"location":"api/overview/#modules","title":"Modules","text":""},{"location":"api/overview/#perturbation-generator","title":"Perturbation Generator","text":"<p>Adversarial perturbation generator for LiDAR point clouds.</p> <p>Uses per-point perturbations with realistic bounds based on research papers. Targets high-curvature regions that are critical for SLAM feature extraction.</p> <p>Location: <code>src/perturbations/perturbation_generator.py</code></p> <p>The <code>PerturbationGenerator</code> class implements state-of-the-art adversarial perturbation techniques for LiDAR point clouds.</p>"},{"location":"api/overview/#src.perturbations.perturbation_generator.PerturbationGenerator.__init__","title":"<code>__init__(max_point_shift=0.05, noise_std=0.02, target_high_curvature=True, curvature_percentile=90.0, max_dropout_rate=0.03, max_ghost_points_ratio=0.02, cluster_shift_std=0.03, n_clusters=5, max_edge_shift=0.08, max_temporal_drift=0.05)</code>","text":"<p>Initialize perturbation generator.</p> <p>Parameters:</p> Name Type Description Default <code>max_point_shift</code> <code>float</code> <p>Maximum displacement per point in meters (default: 5cm)</p> <code>0.05</code> <code>noise_std</code> <code>float</code> <p>Standard deviation of Gaussian noise in meters (default: 2cm)</p> <code>0.02</code> <code>target_high_curvature</code> <code>bool</code> <p>Whether to target high-curvature regions</p> <code>True</code> <code>curvature_percentile</code> <code>float</code> <p>Percentile threshold for high-curvature points</p> <code>90.0</code> <code>max_dropout_rate</code> <code>float</code> <p>Maximum fraction of points to remove</p> <code>0.03</code> <code>max_ghost_points_ratio</code> <code>float</code> <p>Maximum ratio of ghost points to add</p> <code>0.02</code> <code>cluster_shift_std</code> <code>float</code> <p>Std of cluster-based displacement</p> <code>0.03</code> <code>n_clusters</code> <code>int</code> <p>Number of perturbation clusters</p> <code>5</code> <code>max_edge_shift</code> <code>float</code> <p>Maximum shift for detected edge points</p> <code>0.08</code> <code>max_temporal_drift</code> <code>float</code> <p>Maximum accumulated drift per frame</p> <code>0.05</code>"},{"location":"api/overview/#src.perturbations.perturbation_generator.PerturbationGenerator.apply_perturbation","title":"<code>apply_perturbation(point_cloud, params, seed=None)</code>","text":"<p>Apply advanced adversarial perturbation to point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>point_cloud</code> <code>ndarray</code> <p>Input point cloud (N, 4) with [x, y, z, intensity]</p> required <code>params</code> <code>Dict[str, any]</code> <p>Perturbation parameters from encode_perturbation()</p> required <code>seed</code> <code>Optional[int]</code> <p>Random seed for reproducibility</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Perturbed point cloud (M, 4) where M may differ from N</p>"},{"location":"api/overview/#src.perturbations.perturbation_generator.PerturbationGenerator.compute_chamfer_distance","title":"<code>compute_chamfer_distance(original, perturbed)</code>","text":"<p>Compute Chamfer distance between original and perturbed point clouds.</p> <p>Uses the standard bidirectional formula: CD(A, B) = (1/|A|) * \u03a3 min ||a - b||\u00b2 + (1/|B|) * \u03a3 min ||b - a||\u00b2</p> <p>Lower values = more imperceptible perturbation.</p> <p>Parameters:</p> Name Type Description Default <code>original</code> <code>ndarray</code> <p>Original point cloud (N, 3+)</p> required <code>perturbed</code> <code>ndarray</code> <p>Perturbed point cloud (M, 3+)</p> required <p>Returns:</p> Type Description <code>float</code> <p>Chamfer distance (sum of mean squared nearest-neighbor distances)</p>"},{"location":"api/overview/#src.perturbations.perturbation_generator.PerturbationGenerator.compute_curvature","title":"<code>compute_curvature(points, k=10)</code>","text":"<p>Compute local curvature using fast approximation.</p> <p>OPTIMIZED: Uses small sample and vectorized nearest-neighbor assignment.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray</code> <p>Point cloud (N, 3+) XYZ coordinates</p> required <code>k</code> <code>int</code> <p>Number of nearest neighbors</p> <code>10</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Curvature values for each point (N,)</p>"},{"location":"api/overview/#src.perturbations.perturbation_generator.PerturbationGenerator.compute_perturbation_magnitude","title":"<code>compute_perturbation_magnitude(original, perturbed, params)</code>","text":"<p>Compute perturbation magnitude for NSGA-III objective.</p> <p>Combines Chamfer distance (point displacement) with structural changes (dropout/ghost points) to capture both geometric and topological perturbations.</p> <p>Formula: - Chamfer distance captures point displacement - Point count change captures dropout/ghost points as % of original cloud - Total perturbation = sqrt(chamfer\u00b2 + dropout_penalty\u00b2)</p> <p>Parameters:</p> Name Type Description Default <code>original</code> <code>ndarray</code> <p>Original point cloud</p> required <code>perturbed</code> <code>ndarray</code> <p>Perturbed point cloud</p> required <code>params</code> <code>Dict[str, any]</code> <p>Perturbation parameters for decoding dropout/ghost settings</p> required <p>Returns:</p> Type Description <code>float</code> <p>Combined perturbation magnitude in cm (accounts for both displacement and structure)</p>"},{"location":"api/overview/#src.perturbations.perturbation_generator.PerturbationGenerator.detect_edges_and_corners","title":"<code>detect_edges_and_corners(points, k=15)</code>","text":"<p>Detect edge and corner points using eigenvalue analysis.</p> <p>SLACK-inspired: These are the critical points for ICP matching. Perturbing them has maximum impact on scan registration.</p> <p>Classification based on eigenvalue ratios: - Planar: \u03bb1 \u2248 \u03bb2 &gt;&gt; \u03bb3 (surface points) - Edge: \u03bb1 &gt;&gt; \u03bb2 \u2248 \u03bb3 (line features) - Corner: \u03bb1 \u2248 \u03bb2 \u2248 \u03bb3 (3D features)</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray</code> <p>Point cloud (N, 3+)</p> required <code>k</code> <code>int</code> <p>Number of neighbors for local analysis</p> <code>15</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Edge scores for each point (N,) - higher = more edge-like</p>"},{"location":"api/overview/#src.perturbations.perturbation_generator.PerturbationGenerator.encode_perturbation","title":"<code>encode_perturbation(genome)</code>","text":"<p>Encode genome into perturbation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>genome</code> <code>ndarray</code> <p>Normalized parameters in range [-1, 1]</p> required <p>Returns:</p> Type Description <code>Dict[str, any]</code> <p>Dictionary with perturbation parameters</p>"},{"location":"api/overview/#src.perturbations.perturbation_generator.PerturbationGenerator.get_genome_size","title":"<code>get_genome_size()</code>","text":"<p>Get the size of the genome encoding.</p> <p>Genome structure (17 parameters): - [0-2]: Directional bias for per-point noise (normalized direction) - [3]: Noise intensity scale [0, 1] - [4]: Curvature targeting strength [0, 1] - [5]: Point dropout rate [0, 1] - [6]: Ghost points ratio [0, 1] - [7-9]: Cluster perturbation direction - [10]: Cluster perturbation strength [0, 1] - [11]: Spatial correlation of perturbations [0, 1] - [12]: Geometric distortion strength [0, 1] - KEY for ICP attacks - [13]: Edge attack strength [0, 1] - Target edges/corners (SLACK-inspired) - [14]: Temporal drift strength [0, 1] - Accumulating drift (ICP attack) - [15]: Scanline perturbation [0, 1] - ASP-inspired attack - [16]: Strategic ghost placement [0, 1] - Place ghosts near features</p>"},{"location":"api/overview/#src.perturbations.perturbation_generator.PerturbationGenerator.random_genome","title":"<code>random_genome(size=None)</code>","text":"<p>Generate random genome(s).</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>Optional[int]</code> <p>Number of genomes to generate (None for single genome)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Random genome(s) in range [-1, 1]</p>"},{"location":"api/overview/#src.perturbations.perturbation_generator.PerturbationGenerator.reset_temporal_state","title":"<code>reset_temporal_state()</code>","text":"<p>Reset temporal state for new sequence evaluation.</p>"},{"location":"api/overview/#key-methods","title":"Key Methods","text":"Method Description <code>get_genome_size()</code> Returns genome size (17 parameters) <code>encode_perturbation(genome)</code> Converts genome to perturbation parameters <code>apply_perturbation(cloud, params, seed)</code> Applies perturbation to point cloud <code>compute_chamfer_distance(cloud1, cloud2)</code> Computes Chamfer distance between clouds <code>compute_curvature(points)</code> Computes local curvature for targeting <code>detect_edges_and_corners(points)</code> Detects edge/corner points (SLACK-inspired) <code>reset_temporal_state()</code> Resets temporal drift state"},{"location":"api/overview/#genome-structure-17-parameters","title":"Genome Structure (17 parameters)","text":"Index Parameter Range Description 0-2 Noise direction [-1, 1] Directional bias for noise 3 Noise intensity [0, 1] Scaled by <code>noise_std</code> 4 Curvature strength [0, 1] High-curvature targeting 5 Dropout rate [0, 1] Scaled by <code>max_dropout_rate</code> 6 Ghost ratio [0, 1] Scaled by <code>max_ghost_points_ratio</code> 7-9 Cluster direction [-1, 1] Direction for cluster perturbation 10 Cluster strength [0, 1] Cluster perturbation intensity 11 Spatial correlation [0, 1] Correlation of nearby perturbations 12 Geometric distortion [0, 1] ICP attack strength 13 Edge attack [0, 1] SLACK-inspired edge targeting 14 Temporal drift [0, 1] Accumulating drift strength 15 Scanline perturbation [0, 1] ASP-inspired attack 16 Strategic ghost [0, 1] Feature-based ghost placement"},{"location":"api/overview/#metrics","title":"Metrics","text":"<p>Location: <code>src/evaluation/metrics.py</code></p> <p>Functions for computing fitness metrics.</p>"},{"location":"api/overview/#functions","title":"Functions","text":"Function Description <code>compute_localization_error(gt, est, method)</code> Compute ATE/RPE between trajectories <code>compute_imperceptibility(orig, pert, method)</code> Compute perturbation magnitude <code>compute_multi_objective_fitness(...)</code> Combined fitness for NSGA-II <code>normalize_fitness(values, ref_point)</code> Normalize fitness values"},{"location":"api/overview/#ate-computation","title":"ATE Computation","text":"<p>The <code>_compute_ate</code> function implements standard Absolute Trajectory Error:</p> <ol> <li>Umeyama alignment: Rigid alignment (R + t, no scale) of estimated to ground truth</li> <li>RMSE: Root mean squared error of per-pose distances</li> </ol> <pre><code>from src.evaluation.metrics import compute_localization_error\n\nate = compute_localization_error(\n    ground_truth_trajectory,  # (N, 3) array\n    estimated_trajectory,     # (M, 3) array\n    method=\"ate\"              # \"ate\", \"rpe\", or \"final\"\n)\n</code></pre>"},{"location":"api/overview/#data-loaders","title":"Data Loaders","text":"<p>Location: <code>src/utils/data_loaders.py</code></p> <p>Functions for loading point clouds and trajectories.</p>"},{"location":"api/overview/#functions_1","title":"Functions","text":"Function Description <code>load_point_clouds_from_npy(path)</code> Load point cloud sequence <code>load_timestamps_from_npy(path)</code> Load frame timestamps <code>load_trajectory_from_tum(path, ...)</code> Load trajectory (TUM or NPY format)"},{"location":"api/overview/#nsga-iii-optimizer","title":"NSGA-III Optimizer","text":"<p>Location: <code>src/optimization/run_nsga2.py</code></p> <p>Main optimization script using pymoo's NSGA-III algorithm.</p>"},{"location":"api/overview/#key-classes","title":"Key Classes","text":"<p>MOLAEvaluator: ROS2 node that evaluates genomes by running MOLA SLAM.</p> <pre><code>evaluator = MOLAEvaluator(\n    perturbation_generator=generator,\n    ground_truth_trajectory=gt_traj,\n    point_cloud_sequence=clouds,\n    timestamps=timestamps,\n    tf_sequence=tf_data,\n    tf_static=tf_static_data,\n    mola_binary_path=\"/opt/ros/jazzy/bin/mola-cli\",\n    mola_config_path=\"path/to/config.yaml\",\n)\n\n# Evaluate a genome\nneg_ate, chamfer = evaluator.evaluate(genome)\n</code></pre>"},{"location":"api/overview/#command-line-arguments","title":"Command Line Arguments","text":"<pre><code>python src/optimization/run_nsga2.py \\\n    --gt-traj maps/ground_truth_interpolated.npy \\\n    --frames data/frame_sequence.npy \\\n    --pop-size 10 \\\n    --n-gen 20 \\\n    --max-point-shift 0.05 \\\n    --noise-std 0.015 \\\n    --max-dropout 0.15 \\\n    --output src/results/optimized_genome.npy\n</code></pre>"},{"location":"api/overview/#plotting","title":"Plotting","text":"<p>Location: <code>src/plots/plot_nsga2_results.py</code></p> <p>Visualization of optimization results.</p> <pre><code>python src/plots/plot_nsga2_results.py src/results/optimized_genome6\n</code></pre> <p>Generates: - Pareto front plot (ATE vs Chamfer distance) - Best solution analysis - Parameter correlation analysis</p>"},{"location":"api/overview/#usage-examples","title":"Usage Examples","text":""},{"location":"api/overview/#basic-perturbation","title":"Basic Perturbation","text":"<pre><code>import numpy as np\nfrom src.perturbations.perturbation_generator import PerturbationGenerator\n\n# Create generator\ngen = PerturbationGenerator(\n    max_point_shift=0.05,  # 5cm\n    noise_std=0.02,        # 2cm\n    max_dropout_rate=0.15  # 15%\n)\n\n# Generate random genome\ngenome = gen.random_genome()\n\n# Apply perturbation\nparams = gen.encode_perturbation(genome)\nperturbed = gen.apply_perturbation(point_cloud, params, seed=42)\n\n# Measure imperceptibility\nchamfer = gen.compute_chamfer_distance(point_cloud, perturbed)\n</code></pre>"},{"location":"api/overview/#running-optimization","title":"Running Optimization","text":"<pre><code>from pymoo.algorithms.moo.nsga3 import NSGA3\nfrom pymoo.util.ref_dirs import get_reference_directions\n\n# Setup NSGA-III\nref_dirs = get_reference_directions(\"das-dennis\", 2, n_partitions=12)\nalgorithm = NSGA3(\n    pop_size=len(ref_dirs),\n    ref_dirs=ref_dirs,\n)\n\n# Run optimization\nresult = minimize(problem, algorithm, ('n_gen', 20), seed=42)\n\n# Get Pareto front\npareto_front = result.F  # Fitness values\npareto_set = result.X    # Genomes\n</code></pre>"},{"location":"api/overview/#references","title":"References","text":"<ul> <li>NSGA-III: Deb &amp; Jain (2014) - Reference-point based NSGA</li> <li>SLACK: arXiv 2024 - Attacking LiDAR-based SLAM</li> <li>ICP Attack: arXiv 2403.05666 - ICP adversarial perturbations</li> <li>ASP: IEEE 2024 - Attribution-based Scanline Perturbation</li> <li>FLAT: ECCV 2024 - Flux-Aware Imperceptible Adversarial Attacks</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>ROS 2 Jazzy</li> <li>Python 3.11 or higher</li> <li>NVIDIA Isaac Sim</li> <li>MOLA SLAM library</li> <li>pip package manager</li> <li>Git</li> </ul>"},{"location":"getting-started/installation/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/francescacraievich/mola-adversarial-nsga2.git\ncd mola-adversarial-nsga2\n</code></pre>"},{"location":"getting-started/installation/#setup-virtual-environment","title":"Setup Virtual Environment","text":"<pre><code># Create virtual environment\npython3 -m venv .venv\n\n# Activate virtual environment\nsource .venv/bin/activate\n</code></pre>"},{"location":"getting-started/installation/#install-python-dependencies","title":"Install Python Dependencies","text":"<pre><code># Install core dependencies\npip install -r requirements/requirements.txt\n</code></pre> <p>The main dependencies are: - <code>numpy&gt;=1.24.0</code> - Numerical computing - <code>scipy&gt;=1.10.0</code> - Scientific computing (for KDTree) - <code>pymoo&gt;=0.6.0</code> - Multi-objective optimization (NSGA-II) - <code>matplotlib&gt;=3.7.0</code> - Visualization - <code>rosbags&gt;=0.9.0</code> - ROS bag file reading - <code>pytest&gt;=7.0.0</code> - Testing framework - <code>pytest-cov&gt;=4.0.0</code> - Code coverage</p>"},{"location":"getting-started/installation/#install-ros-2-dependencies","title":"Install ROS 2 Dependencies","text":"<pre><code># Source ROS 2\nsource /opt/ros/jazzy/setup.bash\n\n# Install MOLA SLAM\nsudo apt install ros-jazzy-mola-lidar-odometry\n\n# Install mp2p_icp for trajectory export\n# (follow MOLA installation guide)\n</code></pre>"},{"location":"getting-started/installation/#install-isaac-sim","title":"Install Isaac Sim","text":"<p>Refer to the NVIDIA Isaac Sim documentation for installation instructions.</p> <p>Required components: - Isaac Sim base installation - Carter robot asset - LiDAR sensor support</p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code># Activate virtual environment\nsource .venv/bin/activate\n\n# Test Python dependencies\npython -c \"import numpy; import scipy; import pymoo; print('Python deps OK')\"\n\n# Test ROS 2 setup\nsource /opt/ros/jazzy/setup.bash\nros2 pkg list | grep mola\n\n# Expected output:\n# mola_bridge_ros2\n# mola_lidar_odometry\n# mola_pose_list\n# ...\n</code></pre>"},{"location":"getting-started/installation/#directory-structure-after-installation","title":"Directory Structure After Installation","text":"<pre><code>mola-adversarial-nsga2/\n\u251c\u2500\u2500 .venv/                     # Python virtual environment\n\u251c\u2500\u2500 src/                       # Source code\n\u251c\u2500\u2500 scripts/                   # Analysis scripts\n\u251c\u2500\u2500 docs/                      # Documentation\n\u251c\u2500\u2500 maps/                      # SLAM maps (create this)\n\u251c\u2500\u2500 bags/                      # ROS bags (create this)\n\u251c\u2500\u2500 data/                      # Preprocessed data (auto-created)\n\u2514\u2500\u2500 results/                   # Optimization results (auto-created)\n</code></pre> <p>Create missing directories:</p> <pre><code>mkdir -p maps bags\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>After installation, proceed to the Quickstart Guide to: 1. Collect data in Isaac Sim 2. Extract point clouds from bag files 3. Run NSGA-II optimization 4. Analyze results</p>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>This guide walks you through collecting data in Isaac Sim, running NSGA-II optimization, and analyzing the results.</p>"},{"location":"getting-started/quickstart/#overview","title":"Overview","text":"<p>The complete workflow consists of: 1. Data collection in Isaac Sim (simulated robot with LiDAR) 2. Extracting point clouds from ROS2 bag files 3. Running MOLA SLAM to get ground truth trajectory 4. Running NSGA-II optimization to find adversarial perturbations 5. Analyzing results and visualizing point clouds</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have completed the Installation steps: - ROS 2 Jazzy installed and sourced - Python virtual environment activated - MOLA SLAM installed - Isaac Sim installed</p>"},{"location":"getting-started/quickstart/#step-1-data-collection-in-isaac-sim","title":"Step 1: Data Collection in Isaac Sim","text":"<p>Data collection requires running 6 terminals simultaneously. The robot navigates autonomously while collecting LiDAR data.</p>"},{"location":"getting-started/quickstart/#terminal-1-isaac-sim","title":"Terminal 1: Isaac Sim","text":"<pre><code># Launch Isaac Sim (adjust path to your installation)\n~/.local/share/ov/pkg/isaac-sim-4.2.0/isaac-sim.sh\n</code></pre> <p>In Isaac Sim: 1. Open the scene with the Carter robot 2. Enable LiDAR sensor 3. Start the simulation</p>"},{"location":"getting-started/quickstart/#terminal-2-ros2-bridge","title":"Terminal 2: ROS2 Bridge","text":"<pre><code># Source ROS 2\nsource /opt/ros/jazzy/setup.bash\n\n# Launch ROS2 bridge for Isaac Sim\nros2 launch isaac_ros_carter_navigation carter_navigation.launch.py\n</code></pre>"},{"location":"getting-started/quickstart/#terminal-3-ros2-bag-recording","title":"Terminal 3: ROS2 Bag Recording","text":"<pre><code># Source ROS 2\nsource /opt/ros/jazzy/setup.bash\n\n# Create bags directory if it doesn't exist\nmkdir -p bags\n\n# Record LiDAR topic\nros2 bag record -o bags/carter_lidar /point_cloud\n</code></pre>"},{"location":"getting-started/quickstart/#terminal-4-add-intensity-node","title":"Terminal 4: Add Intensity Node","text":"<pre><code># Source ROS 2\nsource /opt/ros/jazzy/setup.bash\n\n# Activate virtual environment\nsource .venv/bin/activate\n\n# Run intensity node to add intensity field to point clouds\npython src/rover_isaacsim/carter_mola_slam/scripts/add_intensity_node.py\n</code></pre> <p>This node subscribes to <code>/point_cloud</code> and republishes to <code>/point_cloud_with_intensity</code>, adding the intensity field that MOLA expects.</p>"},{"location":"getting-started/quickstart/#terminal-5-mola-slam","title":"Terminal 5: MOLA SLAM","text":"<pre><code># Source ROS 2\nsource /opt/ros/jazzy/setup.bash\n\n# Run MOLA LiDAR odometry\nros2 launch mola_lidar_odometry ros2-lidar-odometry.launch.py \\\n  input_sensor_topic:=/point_cloud_with_intensity \\\n  output_trajectory_topic:=/estimated_trajectory\n</code></pre> <p>MOLA will process the LiDAR scans and estimate the robot's trajectory in real-time.</p>"},{"location":"getting-started/quickstart/#terminal-6-trajectory-recording","title":"Terminal 6: Trajectory Recording","text":"<pre><code># Source ROS 2\nsource /opt/ros/jazzy/setup.bash\n\n# Record estimated trajectory\nros2 bag record -o bags/mola_trajectory /estimated_trajectory\n</code></pre>"},{"location":"getting-started/quickstart/#stop-recording","title":"Stop Recording","text":"<p>After the robot completes its navigation: 1. Stop all ROS2 bag recordings (Ctrl+C in terminals 3 and 6) 2. Stop MOLA (Ctrl+C in terminal 5) 3. Stop the intensity node (Ctrl+C in terminal 4) 4. Stop Isaac Sim simulation</p> <p>You should now have two bag files: - <code>bags/carter_lidar/</code> - Contains LiDAR point clouds - <code>bags/mola_trajectory/</code> - Contains MOLA's estimated trajectory</p>"},{"location":"getting-started/quickstart/#step-2-extract-point-clouds-from-bag-file","title":"Step 2: Extract Point Clouds from Bag File","text":"<p>Convert ROS2 bag to numpy format for preprocessing:</p> <pre><code># Activate virtual environment\nsource .venv/bin/activate\n\n# Extract point clouds and transforms\npython src/preprocessing_data/extract_frames_and_tf_from_bag.py \\\n  --bag bags/carter_lidar \\\n  --topic /point_cloud \\\n  --output data/frame_sequence.npy \\\n  --timestamps data/frame_sequence.timestamps.npy \\\n  --tf-topic /tf \\\n  --tf-output data/tf_transforms.npy\n</code></pre> <p>This creates: - <code>data/frame_sequence.npy</code> - List of point cloud arrays (N, 3) with xyz coordinates - <code>data/frame_sequence.timestamps.npy</code> - Timestamps for each frame in nanoseconds - <code>data/tf_transforms.npy</code> - TF transforms for trajectory reconstruction</p>"},{"location":"getting-started/quickstart/#step-3-export-ground-truth-trajectory","title":"Step 3: Export Ground Truth Trajectory","text":"<p>MOLA saves the trajectory in its internal format. Export it to TUM format for evaluation:</p> <pre><code># Source ROS 2\nsource /opt/ros/jazzy/setup.bash\n\n# Export trajectory (adjust paths as needed)\nmp2p_icp_log_to_tum \\\n  --input-log bags/mola_trajectory/trajectory.log \\\n  --output data/ground_truth.tum\n</code></pre> <p>The TUM format contains: <code>timestamp tx ty tz qx qy qz qw</code></p> <p>Alternatively, if MOLA saved the map: <pre><code># Convert MOLA map to trajectory\nmp2p_icp_map_to_tum \\\n  --input-map maps/slam_output.mm \\\n  --output data/ground_truth.tum\n</code></pre></p>"},{"location":"getting-started/quickstart/#step-4-run-nsga-ii-optimization","title":"Step 4: Run NSGA-II Optimization","text":"<p>Now you can run the optimization to find adversarial perturbations:</p> <pre><code># Activate virtual environment\nsource .venv/bin/activate\n\n# Run NSGA-II (400 evaluations: 20 generations \u00d7 20 population)\npython src/optimization/run_nsga2.py --n-gen 20 --pop-size 20\n</code></pre> <p>This will: 1. Load point clouds from <code>data/frame_sequence.npy</code> 2. Load timestamps from <code>data/frame_sequence.timestamps.npy</code> 3. Load ground truth from <code>data/ground_truth.tum</code> 4. Run NSGA-II optimization to find perturbations that maximize ATE 5. Save results to <code>src/results/optimized_genome1.npy</code></p> <p>The optimization takes several hours depending on your hardware. You'll see progress like: <pre><code>Generation 1/20\n  Baseline ATE: 0.6827m (68.27cm)\n  Best ATE: 1.2341m (123.41cm)\n  Best perturbation: 0.0234 m/cm\n\nGeneration 2/20\n  ...\n</code></pre></p>"},{"location":"getting-started/quickstart/#quick-test-run","title":"Quick Test Run","text":"<p>For testing, use fewer evaluations: <pre><code># 4 evaluations: 2 generations \u00d7 2 population\npython src/optimization/run_nsga2.py --n-gen 2 --pop-size 2\n</code></pre></p>"},{"location":"getting-started/quickstart/#step-5-analyze-results","title":"Step 5: Analyze Results","text":"<p>The optimization saves the Pareto front to <code>src/results/optimized_genomeN.npy</code>. Each subsequent run increments the number automatically.</p>"},{"location":"getting-started/quickstart/#understanding-the-results","title":"Understanding the Results","text":"<p>The optimization has two objectives: 1. Maximize ATE - Make MOLA's trajectory as inaccurate as possible 2. Minimize perturbation magnitude - Keep perturbations small and imperceptible</p> <p>The Pareto front shows the trade-off: you can achieve higher ATE with larger perturbations, but the goal is to find solutions that achieve high ATE with minimal perturbation.</p>"},{"location":"getting-started/quickstart/#key-metrics","title":"Key Metrics","text":"<p>From the optimization output: - Baseline ATE: ~68cm (MOLA's natural error on unperturbed data) - Best ATE: The maximum trajectory error achieved - Perturbation budget: Average displacement per point in cm</p>"},{"location":"getting-started/quickstart/#attack-strategy-results","title":"Attack Strategy Results","text":"<p>Based on experiments, the most effective attack strategies are: - Dropout 5%: 18.9% ATE/cm (most efficient) - Gaussian noise: 15.2% ATE/cm - Feature targeting: 12.7% ATE/cm - Ghost points: 8.3% ATE/cm</p> <p>Dropout is the most efficient because removing points: - Breaks feature correspondences - Degrades loop closure detection - Causes accumulated drift over time</p>"},{"location":"getting-started/quickstart/#step-6-visualize-results","title":"Step 6: Visualize Results","text":""},{"location":"getting-started/quickstart/#visualize-optimization-results","title":"Visualize Optimization Results","text":"<p>Plot the Pareto front and convergence:</p> <pre><code># Activate virtual environment\nsource .venv/bin/activate\n\n# Plot NSGA-II results\npython src/plots/plot_nsga2_results.py \\\n  --input src/results/optimized_genome1.npy \\\n  --output src/results/pareto_front.png\n</code></pre> <p>This creates visualizations showing: - Pareto front (ATE vs perturbation magnitude) - Convergence over generations - Best solutions found</p>"},{"location":"getting-started/quickstart/#visualize-perturbations","title":"Visualize Perturbations","text":"<p>Compare original and perturbed point clouds:</p> <pre><code># Plot perturbation effects\npython src/plots/plot_perturbation_results.py \\\n  --original data/frame_sequence.npy \\\n  --perturbed data/temp_perturbed.npy \\\n  --frame 0 \\\n  --output src/results/perturbation_comparison.png\n</code></pre>"},{"location":"getting-started/quickstart/#open-in-cloudcompare-optional","title":"Open in CloudCompare (Optional)","text":"<p>For detailed 3D visualization:</p> <pre><code># Install CloudCompare if needed\nsudo snap install cloudcompare\n\n# Open point clouds (if you have .ply files)\ncloudcompare maps/*.ply\n</code></pre> <p>In CloudCompare: 1. Use point size 2-3 for better visibility 2. Color by intensity or height (Z coordinate) 3. Compare original vs perturbed frames side-by-side</p>"},{"location":"getting-started/quickstart/#understanding-loop-closure","title":"Understanding Loop Closure","text":"<p>Loop closure is critical for SLAM accuracy. When the robot revisits a previously mapped area: - MOLA detects the loop by matching current scan with past scans - It corrects accumulated drift from odometry errors - The trajectory \"snaps\" back to align with the previously mapped location</p> <p>Adversarial perturbations aim to prevent loop closure by: - Removing distinctive features that enable matching - Adding noise to degrade correspondence quality - Creating ghost points that confuse the matcher</p> <p>Without successful loop closure, odometry drift accumulates linearly over time, causing the trajectory error to grow.</p>"},{"location":"getting-started/quickstart/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/quickstart/#mola-collects-0-points","title":"MOLA Collects 0 Points","text":"<p>If MOLA fails to process point clouds: - Check that intensity field is present (use <code>add_intensity_node.py</code>) - Verify point cloud timestamps match MOLA's expected format (nanoseconds) - Check MOLA logs for errors</p> <p>The optimization automatically skips invalid solutions by returning infinite fitness.</p>"},{"location":"getting-started/quickstart/#high-baseline-ate","title":"High Baseline ATE","text":"<p>If baseline ATE is unexpectedly high (&gt;1m): - Check ground truth and estimated trajectory alignment - Verify they use the same coordinate frame - Consider recalibrating MOLA parameters - Visualize trajectories to identify systematic offset</p>"},{"location":"getting-started/quickstart/#out-of-memory","title":"Out of Memory","text":"<p>If optimization runs out of memory: - Reduce population size: <code>--pop-size 10</code> - Reduce number of generations: <code>--n-gen 10</code> - Process fewer frames (modify data loader)</p>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>After completing the quickstart: 1. Read NSGA-II Algorithm to understand the optimization 2. Learn about Perturbation Strategies 3. Understand the Fitness Function 4. Review Baseline Performance expectations</p>"},{"location":"getting-started/quickstart/#summary-of-key-commands","title":"Summary of Key Commands","text":"<pre><code># 1. Data collection (6 terminals - see above)\n\n# 2. Extract point clouds and transforms\npython src/preprocessing_data/extract_frames_and_tf_from_bag.py \\\n  --bag bags/carter_lidar \\\n  --topic /point_cloud \\\n  --output data/frame_sequence.npy \\\n  --timestamps data/frame_sequence.timestamps.npy \\\n  --tf-topic /tf \\\n  --tf-output data/tf_transforms.npy\n\n# 3. Export ground truth\nmp2p_icp_log_to_tum \\\n  --input-log bags/mola_trajectory/trajectory.log \\\n  --output data/ground_truth.tum\n\n# 4. Run optimization (400 evaluations)\npython src/optimization/run_nsga2.py --n-gen 20 --pop-size 20\n\n# 5. Quick test (4 evaluations)\npython src/optimization/run_nsga2.py --n-gen 2 --pop-size 2\n\n# 6. Visualize results\npython src/plots/plot_nsga2_results.py \\\n  --input src/results/optimized_genome1.npy \\\n  --output src/results/pareto_front.png\n</code></pre>"},{"location":"results/baseline/","title":"Baseline Performance","text":""},{"location":"results/baseline/#overview","title":"Overview","text":"<p>This document describes the expected baseline performance of MOLA SLAM on unperturbed data, and compares it with adversarial perturbations discovered by NSGA-II optimization.</p>"},{"location":"results/baseline/#baseline-ate-unperturbed-data","title":"Baseline ATE (Unperturbed Data)","text":"<p>Baseline ATE: ~68cm (0.68 meters)</p> <p>This is MOLA's natural localization error when processing clean, unperturbed LiDAR data from the Isaac Sim simulation.</p>"},{"location":"results/baseline/#why-is-baseline-68cm","title":"Why is baseline 68cm?","text":"<p>MOLA achieves ~68cm ATE on our test trajectory, which is higher than ideal SLAM performance. Possible reasons:</p> <ol> <li>Ground truth misalignment: The ground truth trajectory from Isaac Sim may not be perfectly aligned with MOLA's coordinate frame</li> <li>Odometry drift: Natural accumulation of small errors over the ~11.3 second trajectory</li> <li>Limited loop closure: Short trajectory may not have strong loop closures to correct drift</li> <li>Parameter tuning: MOLA parameters may not be optimally tuned for this specific environment</li> <li>Sensor characteristics: Simulated LiDAR may have different characteristics than what MOLA expects</li> </ol> <p>For comparison, typical MOLA performance: - Ideal conditions (real robot, optimized params): 10-30cm ATE - Good conditions: 30-50cm ATE - Moderate conditions (our case): 60-80cm ATE - Poor conditions (degraded sensors, fast motion): 100cm+ ATE</p>"},{"location":"results/baseline/#baseline-characteristics","title":"Baseline Characteristics","text":"<p>Running MOLA on unperturbed data: - Frames processed: 113 frames (10Hz LiDAR) - Keyframes selected: 49 keyframes (MOLA selects when robot moves) - Trajectory length: ~11.3 seconds - Points per frame: ~50,000 points - Loop closures: 2-3 successful loop closures</p> <p>The baseline provides a reference point for measuring adversarial attack effectiveness.</p>"},{"location":"results/baseline/#adversarial-performance","title":"Adversarial Performance","text":"<p>After NSGA-II optimization (400 evaluations):</p>"},{"location":"results/baseline/#best-absolute-performance","title":"Best Absolute Performance","text":"<ul> <li>Best ATE: 140-150cm</li> <li>Perturbation: 10-15cm average displacement</li> <li>Improvement over baseline: +100% ATE (doubled the error)</li> </ul>"},{"location":"results/baseline/#most-efficient-attack","title":"Most Efficient Attack","text":"<ul> <li>Strategy: Dropout at 5%</li> <li>ATE: 120cm</li> <li>Perturbation: 2.75cm average (5% dropout equivalent)</li> <li>Efficiency: 18.9% ATE increase per cm of perturbation</li> <li>Improvement over baseline: +76% ATE</li> </ul>"},{"location":"results/baseline/#pareto-front-solutions","title":"Pareto Front Solutions","text":"<p>Typical Pareto front after optimization contains 8-12 non-dominated solutions:</p> Solution ATE (cm) Perturbation (cm) Efficiency (%/cm) Strategy A 95 1.0 27.0 Dropout 2% B 110 2.5 16.8 Dropout 4% C 120 2.75 18.9 Dropout 5% D 125 5.0 11.4 Gaussian \u03c3=3cm E 135 7.5 8.9 Feature targeting F 145 12.0 6.4 Mixed strategy <p>Key insights: - Dropout solutions dominate the efficient region of the Pareto front - Gaussian noise is less efficient but achieves moderate ATE - Feature targeting requires more perturbation for similar ATE - Ghost points are not present in the Pareto front (inefficient)</p>"},{"location":"results/baseline/#attack-strategy-comparison","title":"Attack Strategy Comparison","text":""},{"location":"results/baseline/#1-dropout-attack","title":"1. Dropout Attack","text":"<p>Performance: - 5% dropout: 120cm ATE (baseline 68cm) - 10% dropout: 135cm ATE - 20% dropout: 145cm ATE</p> <p>Efficiency: - Most efficient strategy overall - 18.9% ATE increase per cm of perturbation - Dominates the Pareto front</p> <p>Why it works: - Breaks feature correspondences between frames - Degrades loop closure detection - Creates ambiguity in ICP alignment</p>"},{"location":"results/baseline/#2-gaussian-noise-attack","title":"2. Gaussian Noise Attack","text":"<p>Performance: - \u03c3=2cm: 105cm ATE - \u03c3=3cm: 115cm ATE - \u03c3=5cm: 130cm ATE</p> <p>Efficiency: - Second most efficient - 15.2% ATE increase per cm - Good alternative when dropout is detectable</p> <p>Why it works: - Corrupts point position accuracy - Introduces inconsistencies between overlapping scans - Degrades ICP alignment quality</p>"},{"location":"results/baseline/#3-feature-targeting-attack","title":"3. Feature Targeting Attack","text":"<p>Performance: - Moderate targeting: 120cm ATE with 10cm perturbation - Aggressive targeting: 135cm ATE with 15cm perturbation</p> <p>Efficiency: - Third most efficient - 12.7% ATE increase per cm - More sophisticated but less efficient than dropout</p> <p>Why it works: - Prevents correct feature matching - Degrades place recognition - Corrupts map consistency</p>"},{"location":"results/baseline/#4-ghost-points-attack","title":"4. Ghost Points Attack","text":"<p>Performance: - 1000 ghost points: 90cm ATE with 8cm equivalent perturbation - 5000 ghost points: 105cm ATE with 15cm equivalent perturbation</p> <p>Efficiency: - Least efficient strategy - 8.3% ATE increase per cm - Rarely appears in Pareto front</p> <p>Why it's less effective: - MOLA has outlier rejection mechanisms - Ghost points are easier to filter than missing data - Requires large perturbation budget for modest ATE gains</p>"},{"location":"results/baseline/#comparison-with-random-perturbations","title":"Comparison with Random Perturbations","text":"<p>To validate that NSGA-II optimization is beneficial, we compare with random perturbations:</p>"},{"location":"results/baseline/#random-dropout","title":"Random Dropout","text":"<ul> <li>Average ATE: 95cm (\u00b110cm std dev)</li> <li>Perturbation: 5% dropout</li> <li>Efficiency: 9.8% per cm (vs 18.9% for optimized)</li> </ul>"},{"location":"results/baseline/#random-gaussian-noise","title":"Random Gaussian Noise","text":"<ul> <li>Average ATE: 100cm (\u00b18cm std dev)</li> <li>Perturbation: \u03c3=3cm</li> <li>Efficiency: 10.7% per cm (vs 15.2% for optimized)</li> </ul> <p>Conclusion: NSGA-II optimized perturbations are ~2x more efficient than random perturbations with the same strategy.</p>"},{"location":"results/baseline/#temporal-patterns","title":"Temporal Patterns","text":"<p>Analysis of when perturbations are most effective:</p>"},{"location":"results/baseline/#early-trajectory-frames-0-30","title":"Early Trajectory (frames 0-30)","text":"<ul> <li>Perturbations cause immediate odometry error</li> <li>Error accumulates throughout trajectory</li> <li>Most impactful for final ATE</li> </ul>"},{"location":"results/baseline/#middle-trajectory-frames-31-70","title":"Middle Trajectory (frames 31-70)","text":"<ul> <li>Perturbations continue accumulating error</li> <li>Loop closure attempts may fail</li> <li>Moderate impact on final ATE</li> </ul>"},{"location":"results/baseline/#late-trajectory-frames-71-113","title":"Late Trajectory (frames 71-113)","text":"<ul> <li>Perturbations corrupt loop closure detection</li> <li>Prevent correction of accumulated drift</li> <li>High impact if loop closure is prevented</li> </ul> <p>Key finding: Uniform perturbation throughout trajectory is most effective. Targeting specific frames provides marginal improvement.</p>"},{"location":"results/baseline/#loop-closure-analysis","title":"Loop Closure Analysis","text":"<p>Loop closure is the critical vulnerability:</p>"},{"location":"results/baseline/#baseline-no-perturbations","title":"Baseline (no perturbations)","text":"<ul> <li>Loop closures detected: 2-3</li> <li>Successful corrections: 2-3</li> <li>Final drift after correction: 68cm</li> </ul>"},{"location":"results/baseline/#with-5-dropout","title":"With 5% dropout","text":"<ul> <li>Loop closures detected: 1</li> <li>Successful corrections: 0-1</li> <li>Final drift: 120cm</li> </ul>"},{"location":"results/baseline/#with-10-dropout","title":"With 10% dropout","text":"<ul> <li>Loop closures detected: 0</li> <li>Successful corrections: 0</li> <li>Final drift: 135cm</li> </ul> <p>Conclusion: Breaking loop closure is the primary mechanism by which perturbations increase ATE. Without loop closure, odometry drift accumulates linearly.</p>"},{"location":"results/baseline/#error-accumulation-over-time","title":"Error Accumulation Over Time","text":"<p>Trajectory error grows differently with and without perturbations:</p>"},{"location":"results/baseline/#baseline-unperturbed","title":"Baseline (unperturbed)","text":"<pre><code>Time (s)    ATE (cm)\n0           0\n3           15\n6           35\n9           45 (loop closure corrects to 20)\n11.3        68\n</code></pre>"},{"location":"results/baseline/#with-5-dropout_1","title":"With 5% dropout","text":"<pre><code>Time (s)    ATE (cm)\n0           0\n3           25\n6           60\n9           95 (no loop closure correction)\n11.3        120\n</code></pre> <p>Observation: Without loop closure, error accumulates ~3x faster than baseline.</p>"},{"location":"results/baseline/#hardware-and-timing","title":"Hardware and Timing","text":"<p>Baseline measurements on test hardware:</p>"},{"location":"results/baseline/#data-collection","title":"Data Collection","text":"<ul> <li>Isaac Sim: RTX 3080 GPU</li> <li>Collection time: ~15 minutes (including setup)</li> <li>Bag file size: ~500MB for 113 frames</li> </ul>"},{"location":"results/baseline/#optimization","title":"Optimization","text":"<ul> <li>CPU: AMD Ryzen 9 5900X</li> <li>RAM: 32GB</li> <li>Fitness evaluation time: 2-3 minutes per genome</li> <li>Total optimization time (400 evals): 13-20 hours</li> </ul>"},{"location":"results/baseline/#mola-processing","title":"MOLA Processing","text":"<ul> <li>Per-frame processing: ~0.5-1 second</li> <li>Total trajectory: ~60-90 seconds</li> <li>Memory usage: ~2GB peak</li> </ul>"},{"location":"results/baseline/#expected-results-summary","title":"Expected Results Summary","text":"<p>When running the full optimization (400 evaluations), expect:</p> <p>Baseline: - ATE: 68cm \u00b1 5cm - Processing time: 2-3 minutes</p> <p>After optimization: - Best ATE: 140-150cm - Best efficiency: 18.9% per cm (dropout 5%) - Pareto front size: 8-12 solutions - Total runtime: 13-20 hours</p> <p>Validation: If your baseline ATE is significantly different (&gt;100cm or &lt;50cm): 1. Check ground truth trajectory alignment 2. Verify MOLA parameters 3. Ensure timestamp synchronization is correct 4. Visualize trajectories to identify systematic errors</p>"},{"location":"results/baseline/#future-improvements","title":"Future Improvements","text":"<p>Potential ways to improve attack effectiveness:</p> <ol> <li>Adaptive perturbations: Adjust based on MOLA's uncertainty</li> <li>Temporal targeting: Focus on loop closure frames</li> <li>Spatial targeting: Perturb distinctive features</li> <li>Transfer attacks: Optimize on one environment, test on others</li> <li>Physical feasibility: Design perturbations that could be realized physically</li> </ol> <p>Current results show that simple dropout is already highly effective, suggesting that SLAM robustness to missing data is a critical research direction.</p>"},{"location":"results/experiments/","title":"Experimental Results","text":""},{"location":"results/experiments/#overview","title":"Overview","text":"<p>This document summarizes experimental results from NSGA-III optimization runs for adversarial perturbations against MOLA SLAM.</p>"},{"location":"results/experiments/#experimental-setup","title":"Experimental Setup","text":""},{"location":"results/experiments/#environment","title":"Environment","text":"<ul> <li>Simulator: Isaac Sim with simulated rover</li> <li>SLAM System: MOLA LiDAR Odometry (ROS2 Jazzy)</li> <li>LiDAR: Simulated 3D LiDAR at 10Hz</li> <li>Trajectory: ~11.3 seconds, 113 frames</li> </ul>"},{"location":"results/experiments/#optimization-configuration","title":"Optimization Configuration","text":"Parameter Value Algorithm NSGA-III (Das-Dennis reference directions) Population size 10 Generations 20 Reference partitions 12 Genome size 17 parameters"},{"location":"results/experiments/#perturbation-bounds","title":"Perturbation Bounds","text":"Parameter Max Value Point shift 5 cm Noise std 1.5 cm Dropout rate 15% Ghost points ratio 5% Edge shift 8 cm Temporal drift 5 cm/frame"},{"location":"results/experiments/#results-summary","title":"Results Summary","text":""},{"location":"results/experiments/#optimization-runs","title":"Optimization Runs","text":"<p>Multiple optimization runs were conducted to evaluate different attack strategies:</p> Run Generations Best ATE ATE Increase Best Chamfer 6 20 TBD TBD TBD 7 20 TBD TBD TBD 8 20 TBD TBD TBD 9 20 TBD TBD TBD"},{"location":"results/experiments/#baseline-performance","title":"Baseline Performance","text":"<p>Unperturbed MOLA Performance:</p> <ul> <li>ATE (Absolute Trajectory Error): ~0.068m (6.8cm) baseline</li> <li>Processing: 113 frames at 10Hz</li> <li>Loop closures: 2-3 successful detections</li> </ul>"},{"location":"results/experiments/#attack-effectiveness","title":"Attack Effectiveness","text":"<p>The NSGA-III optimization discovers perturbations that significantly increase ATE while maintaining low Chamfer distance (imperceptibility).</p>"},{"location":"results/experiments/#best-attack-strategies-from-previous-runs","title":"Best Attack Strategies (from previous runs)","text":"<ol> <li>Temporal Drift Attack (ICP-inspired)</li> <li>Accumulating bias across frames</li> <li>Breaks loop closure detection</li> <li> <p>Up to 123.5% ATE increase observed</p> </li> <li> <p>Edge Attack (SLACK-inspired)</p> </li> <li>Targets edges/corners critical for ICP matching</li> <li>Shifts points perpendicular to principal direction</li> <li> <p>High efficiency per perturbation budget</p> </li> <li> <p>Scanline Perturbation (ASP-inspired)</p> </li> <li>Perturbs along laser beam directions</li> <li>Physically realistic (simulates particles)</li> <li> <p>Hard to detect</p> </li> <li> <p>Geometric Distortion</p> </li> <li>Systematic range-dependent scaling</li> <li>Breaks ICP convergence assumptions</li> <li>Key parameter for attack success</li> </ol>"},{"location":"results/experiments/#pareto-front-analysis","title":"Pareto Front Analysis","text":""},{"location":"results/experiments/#objectives","title":"Objectives","text":"<p>The optimization minimizes two objectives:</p> <ol> <li>Negative ATE: Minimize negative localization error (maximize attack effectiveness)</li> <li>Chamfer Distance: Minimize perturbation magnitude (maximize imperceptibility)</li> </ol>"},{"location":"results/experiments/#trade-off-curve","title":"Trade-off Curve","text":"<p>The Pareto front represents optimal trade-offs between attack effectiveness and detectability:</p> <pre><code>ATE (m)\n   ^\n   |         * aggressive attacks\n   |       *\n   |     *\n   |   *\n   | * conservative attacks\n   +-------------------------&gt; Chamfer Distance (m)\n</code></pre>"},{"location":"results/experiments/#key-observations","title":"Key Observations","text":"<ol> <li>Efficient frontier: Small perturbations can cause significant ATE increase</li> <li>Diminishing returns: Very large perturbations provide marginal additional ATE gain</li> <li>Attack type matters: Different genome configurations achieve similar fitness through different mechanisms</li> </ol>"},{"location":"results/experiments/#genome-analysis","title":"Genome Analysis","text":""},{"location":"results/experiments/#parameter-importance","title":"Parameter Importance","text":"<p>Analysis of Pareto-optimal genomes reveals which parameters contribute most to attack success:</p> Parameter Correlation with ATE Typical Optimal Range Geometric distortion High 0.6 - 0.9 Temporal drift High 0.5 - 0.8 Edge attack Medium 0.4 - 0.7 Noise intensity Medium 0.3 - 0.6 Dropout rate Low-Medium 0.2 - 0.5 Scanline Medium 0.3 - 0.6"},{"location":"results/experiments/#attack-combinations","title":"Attack Combinations","text":"<p>The most effective attacks combine multiple strategies:</p> <ol> <li>High ATE, High Detectability:</li> <li>All attack parameters maximized</li> <li>ATE increase: 100%+</li> <li> <p>Chamfer distance: High</p> </li> <li> <p>Balanced Attack:</p> </li> <li>Moderate temporal drift + edge attack</li> <li>ATE increase: 50-80%</li> <li> <p>Chamfer distance: Medium</p> </li> <li> <p>Stealthy Attack:</p> </li> <li>Low intensity across all parameters</li> <li>ATE increase: 20-40%</li> <li>Chamfer distance: Very low</li> </ol>"},{"location":"results/experiments/#comparison-with-baseline-methods","title":"Comparison with Baseline Methods","text":""},{"location":"results/experiments/#random-perturbations","title":"Random Perturbations","text":"<p>Random perturbations with same magnitude achieve ~50% of optimized attack effectiveness.</p>"},{"location":"results/experiments/#grid-search","title":"Grid Search","text":"<p>Exhaustive grid search over single parameters is less efficient than NSGA-III multi-parameter optimization.</p>"},{"location":"results/experiments/#single-objective-optimization","title":"Single-Objective Optimization","text":"<p>Optimizing ATE only (ignoring imperceptibility) produces easily detectable attacks with marginal additional ATE gain.</p>"},{"location":"results/experiments/#reproducibility","title":"Reproducibility","text":""},{"location":"results/experiments/#running-experiments","title":"Running Experiments","text":"<pre><code># Run optimization\npython src/optimization/run_nsga2.py \\\n    --pop-size 10 \\\n    --n-gen 20 \\\n    --seed 42\n\n# Analyze results\npython src/plots/plot_nsga2_results.py src/results/optimized_genome&lt;N&gt;\n</code></pre>"},{"location":"results/experiments/#output-files","title":"Output Files","text":"<p>Each run produces:</p> <ul> <li><code>optimized_genome&lt;N&gt;.npy</code> - Best genome</li> <li><code>optimized_genome&lt;N&gt;.pareto_front.npy</code> - Pareto front fitness values</li> <li><code>optimized_genome&lt;N&gt;.pareto_set.npy</code> - Pareto front genomes</li> <li><code>optimized_genome&lt;N&gt;.all_points.npy</code> - All evaluated points</li> <li><code>nsga2_pareto_front_run&lt;N&gt;.png</code> - Visualization</li> </ul>"},{"location":"results/experiments/#future-work","title":"Future Work","text":"<ol> <li>More generations: Run for 50+ generations to improve convergence</li> <li>Larger population: Increase population size for better Pareto front coverage</li> <li>Transfer attacks: Test optimized attacks on different trajectories</li> <li>Defense evaluation: Measure robustness improvements from detected attacks</li> <li>Physical feasibility: Assess which attacks could be realized in real environments</li> </ol>"},{"location":"results/experiments/#references","title":"References","text":"<ul> <li>NSGA-III Algorithm</li> <li>Perturbation Strategies</li> <li>Baseline Performance</li> </ul>"},{"location":"user-guide/fitness/","title":"Fitness Evaluation","text":""},{"location":"user-guide/fitness/#overview","title":"Overview","text":"<p>Fitness evaluation is the core of the NSGA-II optimization process. For each candidate solution (genome), we need to measure how well it achieves our two objectives: maximizing localization error while minimizing perturbation magnitude.</p> <p>This evaluation happens hundreds of times during optimization (400 evaluations = 20 generations \u00d7 20 population), making it the most computationally expensive component of the system.</p>"},{"location":"user-guide/fitness/#two-objectives","title":"Two Objectives","text":""},{"location":"user-guide/fitness/#objective-1-maximize-localization-error-ate","title":"Objective 1: Maximize Localization Error (ATE)","text":"<p>The primary goal is to degrade MOLA's localization accuracy as much as possible. We measure this using Absolute Trajectory Error (ATE).</p> <p>ATE Definition: ATE is the root mean square error (RMSE) between the estimated trajectory and ground truth trajectory after optimal alignment.</p> <p>Formula: <pre><code>ATE = sqrt(1/N * \u03a3 ||p_i - q_i||\u00b2)\n</code></pre></p> <p>Where: - N = number of trajectory poses - p_i = ground truth position at pose i - q_i = estimated position at pose i - ||\u00b7|| = Euclidean distance (L2 norm)</p> <p>Interpretation: - Higher ATE = More trajectory error = Better attack - Baseline ATE \u2248 68cm (MOLA's natural error on unperturbed data) - Target ATE \u2248 120-150cm (after perturbations)</p> <p>NSGA-II tries to maximize this objective.</p>"},{"location":"user-guide/fitness/#objective-2-minimize-perturbation-magnitude","title":"Objective 2: Minimize Perturbation Magnitude","text":"<p>The secondary goal is to keep perturbations as small as possible to avoid detection.</p> <p>Perturbation Magnitude: We measure the average displacement applied to points across all frames.</p> <p>Formula: <pre><code>Perturbation = (1/M) * \u03a3 ||\u03b4_j||\n</code></pre></p> <p>Where: - M = total number of perturbed points - \u03b4_j = displacement vector for point j - ||\u00b7|| = Euclidean distance (L2 norm)</p> <p>Special case for dropout: When points are removed (dropout), we count the missing point as having infinite displacement for measurement purposes, but use the dropout rate as a proxy: <pre><code>Perturbation (dropout) = dropout_rate * average_point_spacing\n</code></pre></p> <p>Interpretation: - Lower perturbation = More stealthy = Better - Typical perturbations: 1-15cm average displacement - Physical constraint: &lt; 50cm maximum displacement per point</p> <p>NSGA-II tries to minimize this objective.</p>"},{"location":"user-guide/fitness/#evaluation-pipeline","title":"Evaluation Pipeline","text":"<p>For each genome in the population, the fitness evaluation follows these steps:</p>"},{"location":"user-guide/fitness/#step-1-load-data","title":"Step 1: Load Data","text":"<pre><code># Load point cloud frames\nframes = np.load('data/frame_sequence.npy', allow_pickle=True)  # 113 frames\n\n# Load timestamps\ntimestamps = np.load('data/frame_sequence.timestamps.npy')  # nanoseconds\n\n# Load ground truth trajectory\nground_truth = load_trajectory_from_tum('data/ground_truth.tum')\n</code></pre>"},{"location":"user-guide/fitness/#step-2-decode-genome","title":"Step 2: Decode Genome","text":"<p>The genome encodes the perturbation strategy and parameters:</p> <pre><code># Example genome: [strategy_id, param1, param2, ...]\n# strategy_id: 0=dropout, 1=gaussian, 2=feature, 3=ghost\n# params depend on strategy\n\nstrategy = int(genome[0])\nif strategy == 0:  # Dropout\n    dropout_rate = genome[1]  # 0-100%\nelif strategy == 1:  # Gaussian noise\n    noise_sigma = genome[1]  # 0-10cm\n# ... etc\n</code></pre>"},{"location":"user-guide/fitness/#step-3-apply-perturbations","title":"Step 3: Apply Perturbations","text":"<p>Apply the decoded perturbations to all frames:</p> <pre><code>perturbed_frames = []\ntotal_perturbation = 0.0\n\nfor frame in frames:\n    perturbed_frame, perturbation_amount = apply_perturbation(\n        frame, strategy, params\n    )\n    perturbed_frames.append(perturbed_frame)\n    total_perturbation += perturbation_amount\n\navg_perturbation = total_perturbation / len(frames)\n</code></pre>"},{"location":"user-guide/fitness/#step-4-write-temporary-files","title":"Step 4: Write Temporary Files","text":"<p>MOLA needs data in ROS2 format, so we write perturbed frames to temporary files:</p> <pre><code># Write perturbed frames to .npy\ntemp_frames = 'data/temp_perturbed.npy'\nnp.save(temp_frames, perturbed_frames)\n\n# Copy timestamps (unchanged)\ntemp_timestamps = 'data/temp_perturbed.timestamps.npy'\nshutil.copy('data/frame_sequence.timestamps.npy', temp_timestamps)\n</code></pre>"},{"location":"user-guide/fitness/#step-5-run-mola-slam","title":"Step 5: Run MOLA SLAM","text":"<p>Launch MOLA to process the perturbed point clouds:</p> <pre><code># Create ROS2 node\nros2 = subprocess.Popen(['ros2', 'launch', 'mola_lidar_odometry', ...])\n\n# Publish perturbed frames with timestamps\nfor frame, timestamp in zip(perturbed_frames, timestamps):\n    publish_pointcloud(frame, timestamp)\n    time.sleep(0.1)  # 10Hz\n\n# Wait for MOLA to complete\nros2.wait(timeout=60)\n</code></pre> <p>MOLA outputs an estimated trajectory.</p>"},{"location":"user-guide/fitness/#step-6-extract-estimated-trajectory","title":"Step 6: Extract Estimated Trajectory","text":"<p>Read MOLA's output trajectory:</p> <pre><code># MOLA writes trajectory to file\nestimated_traj = load_trajectory_from_tum('maps/estimated_trajectory.tum')\n\n# Check if MOLA succeeded\nif len(estimated_traj) &lt; 10:\n    # MOLA failed - return invalid fitness\n    return (np.inf, np.inf)\n</code></pre> <p>If MOLA collects fewer than 10 poses, something went wrong (likely too much dropout or noise). We return infinite fitness to exclude this solution.</p>"},{"location":"user-guide/fitness/#step-7-align-trajectories","title":"Step 7: Align Trajectories","text":"<p>Before computing ATE, we need to align the trajectories:</p> <pre><code>from scipy.spatial.transform import Rotation\n\ndef align_trajectories(estimated, ground_truth):\n    \"\"\"Align estimated trajectory to ground truth using Umeyama algorithm.\"\"\"\n    # Compute optimal rotation and translation\n    R, t, scale = umeyama_alignment(estimated, ground_truth)\n\n    # Apply transformation\n    aligned = scale * (estimated @ R.T) + t\n\n    return aligned\n</code></pre> <p>This accounts for: - Different coordinate frames - Different starting positions - Scale differences (usually scale=1 for MOLA)</p>"},{"location":"user-guide/fitness/#step-8-compute-ate","title":"Step 8: Compute ATE","text":"<p>Calculate the trajectory error:</p> <pre><code>def compute_ate(estimated, ground_truth):\n    \"\"\"Compute Absolute Trajectory Error (RMSE).\"\"\"\n    # Align trajectories first\n    aligned = align_trajectories(estimated, ground_truth)\n\n    # Ensure same length (interpolate if needed)\n    if len(aligned) != len(ground_truth):\n        aligned = interpolate_trajectory(aligned, len(ground_truth))\n\n    # Compute RMSE\n    squared_errors = np.sum((aligned - ground_truth) ** 2, axis=1)\n    ate = np.sqrt(np.mean(squared_errors))\n\n    return ate\n</code></pre>"},{"location":"user-guide/fitness/#step-9-return-fitness","title":"Step 9: Return Fitness","text":"<p>Return both objectives to NSGA-II:</p> <pre><code>fitness = (\n    -ate,  # Negative because pymoo minimizes (we want to maximize ATE)\n    avg_perturbation  # Minimize perturbation\n)\nreturn fitness\n</code></pre> <p>Note: pymoo minimizes all objectives by default, so we negate ATE to convert maximization to minimization.</p>"},{"location":"user-guide/fitness/#handling-invalid-solutions","title":"Handling Invalid Solutions","text":"<p>Some perturbations cause MOLA to fail completely:</p> <p>Failure cases: - 100% dropout: No points to process - Extreme noise: All points displaced far from original positions - Too many ghost points: Memory overflow</p> <p>Handling strategy: Return infinite fitness for both objectives:</p> <pre><code>if mola_failed or len(estimated_traj) &lt; 10:\n    return (np.inf, np.inf)\n</code></pre> <p>NSGA-II automatically excludes these solutions from the Pareto front. This is better than using a penalty value (like 50.0) because penalties can distort the Pareto front.</p>"},{"location":"user-guide/fitness/#performance-optimization","title":"Performance Optimization","text":"<p>Fitness evaluation is expensive (several minutes per evaluation). Optimizations:</p>"},{"location":"user-guide/fitness/#1-caching-baseline","title":"1. Caching Baseline","text":"<p>Compute baseline ATE once and reuse:</p> <pre><code>if not hasattr(self, '_baseline_ate'):\n    self._baseline_ate = evaluate_unperturbed()\n</code></pre>"},{"location":"user-guide/fitness/#2-early-termination","title":"2. Early Termination","text":"<p>If MOLA shows signs of failing, terminate early:</p> <pre><code>if len(collected_points) == 0:\n    # MOLA collected nothing - stop early\n    terminate_mola()\n    return (np.inf, np.inf)\n</code></pre>"},{"location":"user-guide/fitness/#3-parallel-evaluation","title":"3. Parallel Evaluation","text":"<p>Future work: Evaluate multiple genomes in parallel using multiprocessing.</p> <p>Currently not implemented because MOLA uses ROS2, which complicates parallelization.</p>"},{"location":"user-guide/fitness/#metrics-tracking","title":"Metrics Tracking","text":"<p>During optimization, we track several metrics:</p> <pre><code># Best ATE achieved so far\nbest_ate = max(population, key=lambda x: -x.F[0])\n\n# Most efficient solution (highest ATE per cm)\nefficiency = [-f[0] / f[1] for f in population.F]\nbest_efficiency = max(efficiency)\n\n# Pareto front size\npareto_size = len(population[population.rank == 0])\n</code></pre> <p>These metrics help monitor convergence and identify the most effective attacks.</p>"},{"location":"user-guide/fitness/#baseline-performance","title":"Baseline Performance","text":"<p>Before optimization, we evaluate baseline performance on unperturbed data:</p> <pre><code>baseline_ate = evaluate_unperturbed()\nprint(f\"Baseline ATE: {baseline_ate:.4f}m ({baseline_ate*100:.2f}cm)\")\n</code></pre> <p>Expected baseline: - Ideal conditions: 30-50cm - Realistic conditions: 60-80cm - Poor conditions: 100cm+</p> <p>Our baseline is ~68cm, which suggests: - Ground truth may have slight misalignment - MOLA parameters may not be optimal - Natural drift accumulation without perfect loop closure</p>"},{"location":"user-guide/fitness/#understanding-ate-values","title":"Understanding ATE Values","text":"<p>What do different ATE values mean?</p> ATE Interpretation Quality 0-30cm Excellent SLAM performance Professional-grade 30-60cm Good performance Acceptable for robotics 60-100cm Moderate drift Usable but degraded 100-150cm Significant drift Unreliable localization 150cm+ Severe failure Unusable <p>Our goal is to push ATE from ~68cm (baseline) to 120-150cm (severely degraded).</p>"},{"location":"user-guide/fitness/#efficiency-metric","title":"Efficiency Metric","text":"<p>Beyond absolute ATE, we care about efficiency: how much ATE per unit of perturbation?</p> <p>Efficiency = (ATE - baseline_ATE) / perturbation_magnitude</p> <p>Example: - Solution A: ATE=120cm, pert=5cm \u2192 efficiency = (120-68)/5 = 10.4%/cm - Solution B: ATE=140cm, pert=10cm \u2192 efficiency = (140-68)/10 = 7.2%/cm</p> <p>Solution A is more efficient despite lower absolute ATE.</p> <p>This metric reveals that dropout at 5% is most efficient (18.9%/cm).</p>"},{"location":"user-guide/fitness/#debugging-failed-evaluations","title":"Debugging Failed Evaluations","text":"<p>If many evaluations return infinite fitness:</p> <ol> <li>Check MOLA logs: Look for errors or warnings</li> <li>Visualize perturbations: Ensure they're reasonable</li> <li>Reduce perturbation magnitude: May be too aggressive</li> <li>Check timestamps: MOLA requires proper timestamp synchronization</li> <li>Verify data files: Ensure frames and timestamps are valid</li> </ol> <p>Common issues: - Missing intensity field in point clouds (use <code>add_intensity_node.py</code>) - Timestamp misalignment (MOLA expects nanoseconds) - Extreme perturbations that violate physical constraints</p>"},{"location":"user-guide/fitness/#implementation","title":"Implementation","text":"<p>The fitness evaluator is implemented in <code>src/optimization/run_nsga2.py</code> as a pymoo Problem:</p> <pre><code>class AdversarialPerturbationProblem(ElementwiseProblem):\n    def __init__(self):\n        super().__init__(\n            n_var=genome_length,\n            n_obj=2,  # ATE and perturbation\n            n_constr=0,\n            xl=lower_bounds,\n            xu=upper_bounds\n        )\n\n    def _evaluate(self, x, out, *args, **kwargs):\n        # x is the genome\n        ate, perturbation = evaluate_genome(x)\n\n        # Return objectives (both minimization)\n        out[\"F\"] = [-ate, perturbation]\n</code></pre>"},{"location":"user-guide/fitness/#summary","title":"Summary","text":"<p>Fitness evaluation measures two competing objectives:</p> <ol> <li>ATE (maximize): How much MOLA's trajectory deviates from ground truth</li> <li>Perturbation (minimize): Average displacement applied to points</li> </ol> <p>The evaluation pipeline: 1. Apply perturbations to point clouds 2. Run MOLA SLAM 3. Extract estimated trajectory 4. Align with ground truth 5. Compute ATE 6. Return fitness to NSGA-II</p> <p>Key considerations: - Invalid solutions return infinite fitness - Baseline ATE is ~68cm - Target ATE is 120-150cm - Most efficient attack: dropout at 5% (18.9%/cm) - Evaluation takes several minutes per genome</p>"},{"location":"user-guide/nsga2/","title":"NSGA-III Algorithm","text":""},{"location":"user-guide/nsga2/#overview","title":"Overview","text":"<p>This project uses NSGA-III (Non-dominated Sorting Genetic Algorithm III), an advanced multi-objective evolutionary algorithm designed for better handling of many-objective optimization problems. NSGA-III improves upon NSGA-II by using reference-point based selection instead of crowding distance, providing better diversity maintenance along the Pareto front.</p> <p>In this project, we optimize two competing objectives: 1. Maximize SLAM localization error (attack effectiveness) 2. Minimize perturbation magnitude (imperceptibility)</p> <p>Unlike single-objective optimization that finds one best solution, NSGA-III finds a set of Pareto-optimal solutions that represent different trade-offs between the objectives.</p>"},{"location":"user-guide/nsga2/#why-multi-objective-optimization","title":"Why Multi-Objective Optimization?","text":"<p>In adversarial attacks on SLAM systems, we face two competing objectives:</p> <ol> <li>Maximize ATE (Absolute Trajectory Error) - We want to degrade MOLA's localization accuracy as much as possible</li> <li>Minimize perturbation magnitude - We want perturbations to be small and imperceptible</li> </ol> <p>You cannot optimize both simultaneously because: - Larger perturbations cause more damage but are easier to detect - Smaller perturbations are stealthier but cause less damage</p> <p>NSGA-II finds the Pareto front: the set of solutions where improving one objective requires worsening the other.</p>"},{"location":"user-guide/nsga2/#key-concepts","title":"Key Concepts","text":""},{"location":"user-guide/nsga2/#pareto-dominance","title":"Pareto Dominance","text":"<p>Solution A dominates solution B if: - A is better than B in at least one objective - A is not worse than B in any objective</p> <p>Example: - Solution A: ATE = 1.5m, perturbation = 2cm - Solution B: ATE = 1.2m, perturbation = 3cm - A dominates B (higher ATE and lower perturbation)</p>"},{"location":"user-guide/nsga2/#pareto-front","title":"Pareto Front","text":"<p>The Pareto front is the set of non-dominated solutions. These are the \"best\" solutions where you cannot improve one objective without worsening another.</p> <p>In our case, the Pareto front shows: - Minimum perturbation needed to achieve a given ATE - Maximum ATE achievable with a given perturbation budget</p>"},{"location":"user-guide/nsga2/#non-dominated-sorting","title":"Non-dominated Sorting","text":"<p>NSGA-II ranks solutions into fronts: - Front 1: Non-dominated solutions (the Pareto front) - Front 2: Solutions dominated only by Front 1 - Front 3: Solutions dominated only by Fronts 1 and 2 - And so on...</p> <p>During selection, Front 1 solutions are preferred, then Front 2, etc.</p>"},{"location":"user-guide/nsga2/#reference-points-nsga-iii","title":"Reference Points (NSGA-III)","text":"<p>NSGA-III uses reference points instead of crowding distance for diversity maintenance. Reference points are uniformly distributed on a normalized hyperplane and guide the search toward well-spread solutions.</p> <p>Das-Dennis method: We use Das-Dennis reference directions to generate evenly-spaced reference points: - For 2 objectives with 12 partitions: generates 13 reference points - Each solution is associated with its nearest reference point - Selection favors solutions in underrepresented regions</p> <p>This provides better diversity than crowding distance, especially for problems with 3+ objectives.</p>"},{"location":"user-guide/nsga2/#crowding-distance-legacy-nsga-ii","title":"Crowding Distance (Legacy - NSGA-II)","text":"<p>NSGA-II used crowding distance to maintain diversity:</p> <ul> <li>Large crowding distance: Solution is in a sparse region (preferred)</li> <li>Small crowding distance: Solution has many neighbors (less preferred)</li> </ul> <p>NSGA-III's reference-point approach is generally more effective for maintaining spread along the Pareto front.</p>"},{"location":"user-guide/nsga2/#algorithm-steps","title":"Algorithm Steps","text":""},{"location":"user-guide/nsga2/#1-initialization","title":"1. Initialization","text":"<p>Generate an initial population of random solutions. Each solution is a \"genome\" encoding perturbations for the point cloud.</p> <p>In our implementation: - Population size: 10-13 individuals (based on reference directions) - Reference partitions: 12 (Das-Dennis) - Each genome has 17 parameters encoding multiple attack strategies</p>"},{"location":"user-guide/nsga2/#2-fitness-evaluation","title":"2. Fitness Evaluation","text":"<p>Evaluate each individual by: 1. Apply perturbations to point clouds 2. Run MOLA SLAM on perturbed data 3. Compare estimated trajectory with ground truth 4. Calculate ATE (objective 1) and perturbation magnitude (objective 2)</p> <p>This is the most computationally expensive step, taking several minutes per evaluation.</p>"},{"location":"user-guide/nsga2/#3-non-dominated-sorting","title":"3. Non-dominated Sorting","text":"<p>Rank all solutions into fronts based on dominance relationships. Solutions in Front 1 are the current best approximation of the Pareto front.</p>"},{"location":"user-guide/nsga2/#4-crowding-distance-calculation","title":"4. Crowding Distance Calculation","text":"<p>For each front, calculate crowding distance to identify which solutions maintain diversity along the front.</p>"},{"location":"user-guide/nsga2/#5-tournament-selection","title":"5. Tournament Selection","text":"<p>Select parents for reproduction using tournament selection: 1. Randomly pick two individuals 2. Select the one with better rank (lower front number) 3. If tied, select the one with larger crowding distance</p> <p>This favors both quality (low rank) and diversity (high crowding distance).</p>"},{"location":"user-guide/nsga2/#6-crossover-and-mutation","title":"6. Crossover and Mutation","text":"<p>Create offspring through genetic operators:</p> <p>Crossover: Combine two parent genomes - Example: Take attack strategy from parent A, parameters from parent B - Crossover probability: 90%</p> <p>Mutation: Randomly modify genome components - Example: Change dropout rate from 5% to 7% - Mutation probability: 10%</p>"},{"location":"user-guide/nsga2/#7-combine-populations","title":"7. Combine Populations","text":"<p>Merge parent population (size N) with offspring population (size N) to create a combined pool of size 2N.</p>"},{"location":"user-guide/nsga2/#8-environmental-selection","title":"8. Environmental Selection","text":"<p>Select the best N individuals for the next generation: 1. Sort combined population into fronts 2. Add entire fronts to next generation until full 3. If the last front doesn't fit completely, use crowding distance to select the most diverse individuals</p>"},{"location":"user-guide/nsga2/#9-termination","title":"9. Termination","text":"<p>Repeat steps 2-8 for a fixed number of generations (typically 20 generations).</p> <p>Final output is Front 1 from the last generation, which approximates the true Pareto front.</p>"},{"location":"user-guide/nsga2/#parameters","title":"Parameters","text":"<p>Key parameters in our NSGA-III implementation:</p> <ul> <li>Population size: 10-13 individuals (determined by reference directions)</li> <li>Reference partitions: 12 (Das-Dennis method)</li> <li>Number of generations: 20 (for ~200 total evaluations)</li> <li>Crossover probability: 0.9 (SBX crossover, eta=15)</li> <li>Mutation probability: Polynomial mutation (eta=20)</li> </ul> <p>For quick testing, use smaller values: - Population size: 4 - Generations: 5 - Reference partitions: 3</p>"},{"location":"user-guide/nsga2/#genome-encoding-17-parameters","title":"Genome Encoding (17 Parameters)","text":"<p>Each individual is encoded as a 17-parameter genome that combines multiple attack strategies inspired by recent research (SLACK, ICP Attack, ASP, FLAT):</p> Index Parameter Range Description 0-2 Noise direction [-1, 1] Directional bias for noise (x, y, z) 3 Noise intensity [0, 1] Scaled by <code>noise_std</code> config 4 Curvature strength [0, 1] High-curvature point targeting 5 Dropout rate [0, 1] Scaled by <code>max_dropout_rate</code> 6 Ghost ratio [0, 1] Scaled by <code>max_ghost_points_ratio</code> 7-9 Cluster direction [-1, 1] Direction for cluster perturbation 10 Cluster strength [0, 1] Cluster perturbation intensity 11 Spatial correlation [0, 1] Correlation of nearby perturbations 12 Geometric distortion [0, 1] Range-dependent scaling (KEY for ICP) 13 Edge attack [0, 1] SLACK-inspired edge/corner targeting 14 Temporal drift [0, 1] Accumulating drift (breaks loop closure) 15 Scanline perturbation [0, 1] ASP-inspired along-beam perturbation 16 Strategic ghost [0, 1] Feature-based ghost point placement"},{"location":"user-guide/nsga2/#attack-combinations","title":"Attack Combinations","text":"<p>The genome allows combining multiple strategies simultaneously:</p> <ul> <li>High ATE, High Detectability: Maximize all parameters</li> <li>Balanced Attack: Moderate temporal drift + edge attack</li> <li>Stealthy Attack: Low intensity across all parameters</li> </ul> <p>The genome is represented as a numpy array in range [-1, 1] that pymoo manipulates with genetic operators.</p>"},{"location":"user-guide/nsga2/#constraint-handling","title":"Constraint Handling","text":"<p>Physical constraints are enforced: - Maximum perturbation per point: 50cm (points moved beyond this are unrealistic) - Dropout rate: 0-100% (cannot remove more than all points) - Noise standard deviation: 0-10cm (larger values create obvious artifacts)</p> <p>Constraint violations are handled by: 1. Returning infinite fitness (solution is automatically excluded from Pareto front) 2. Repairing infeasible solutions to nearest feasible point</p>"},{"location":"user-guide/nsga2/#convergence","title":"Convergence","text":"<p>NSGA-II typically converges to a good approximation of the Pareto front within 20-50 generations. You can monitor convergence by tracking:</p> <ol> <li>Hypervolume: Volume of objective space dominated by Pareto front (should increase)</li> <li>Best ATE: Maximum ATE achieved (should increase)</li> <li>Best efficiency: Highest ATE per cm of perturbation (should increase)</li> </ol> <p>In practice, we observe: - Baseline ATE: 68cm (unperturbed) - After 20 generations: 120-150cm ATE with 5-10cm perturbations - Convergence plateaus around generation 15-20</p>"},{"location":"user-guide/nsga2/#comparison-with-single-objective-optimization","title":"Comparison with Single-Objective Optimization","text":"<p>Why not use single-objective optimization (e.g., maximize ATE only)?</p> <p>Single-objective approach: - Would find solutions with very high ATE but also very large perturbations - No control over perturbation budget - Misses efficient solutions with good ATE/perturbation trade-offs</p> <p>NSGA-II multi-objective approach: - Finds entire Pareto front with diverse trade-offs - Allows choosing solution based on perturbation budget constraints - Identifies most efficient attack strategies (highest ATE per cm) - Discovers that dropout is more efficient than noise or ghost points</p>"},{"location":"user-guide/nsga2/#interpreting-results","title":"Interpreting Results","text":"<p>After optimization, the Pareto front shows:</p> <p>Example solutions: 1. Solution A: ATE = 0.95m, perturbation = 1cm (conservative attack) 2. Solution B: ATE = 1.30m, perturbation = 5cm (balanced attack) 3. Solution C: ATE = 1.65m, perturbation = 12cm (aggressive attack)</p> <p>Key insight: Dropout at 5% is most efficient - Achieves 18.9% ATE increase per cm of perturbation - Outperforms Gaussian noise (15.2%), feature targeting (12.7%), and ghost points (8.3%) - Removing points breaks feature correspondences and degrades loop closure</p>"},{"location":"user-guide/nsga2/#advantages-of-nsga-ii","title":"Advantages of NSGA-II","text":"<ol> <li>No weight tuning: Unlike weighted sum approaches, NSGA-II doesn't require manually tuning weights for objectives</li> <li>Diverse solutions: Maintains multiple solutions with different trade-offs</li> <li>Robust: Works well even when objectives have different scales or units</li> <li>Parallelizable: Fitness evaluations are independent and can be parallelized</li> </ol>"},{"location":"user-guide/nsga2/#limitations","title":"Limitations","text":"<ol> <li>Computational cost: Requires hundreds of fitness evaluations, each taking minutes</li> <li>Stochastic: Results vary between runs due to randomness</li> <li>Scaling: Performance degrades with &gt;3 objectives (not an issue here)</li> <li>Local optima: May get stuck in local Pareto fronts, though crossover helps escape</li> </ol>"},{"location":"user-guide/nsga2/#implementation-details","title":"Implementation Details","text":"<p>Our implementation uses pymoo, a Python framework for multi-objective optimization:</p> <pre><code>from pymoo.algorithms.moo.nsga3 import NSGA3\nfrom pymoo.util.ref_dirs import get_reference_directions\nfrom pymoo.optimize import minimize\n\n# Generate Das-Dennis reference directions\nref_dirs = get_reference_directions(\"das-dennis\", 2, n_partitions=12)\n\nalgorithm = NSGA3(\n    pop_size=len(ref_dirs),  # Population size from reference directions\n    ref_dirs=ref_dirs,\n)\n\nresult = minimize(\n    problem,\n    algorithm,\n    ('n_gen', 20),\n    seed=42,\n    verbose=True\n)\n\n# Access results\npareto_front = result.F  # Fitness values (N, 2)\npareto_set = result.X    # Genomes (N, 17)\n</code></pre> <p>The problem definition includes: - Number of variables: 17 (genome length) - Variable bounds: [-1, 1] for all parameters - Number of objectives: 2 (negative ATE, Chamfer distance) - Evaluation function: applies perturbations and runs MOLA SLAM</p>"},{"location":"user-guide/nsga2/#nsga-iii-vs-nsga-ii","title":"NSGA-III vs NSGA-II","text":"Feature NSGA-II NSGA-III Diversity mechanism Crowding distance Reference points Scalability Good for 2-3 objectives Better for many objectives Parameter tuning Minimal Reference partitions Pareto front coverage Can have gaps More uniform <p>We use NSGA-III because: 1. Better diversity maintenance along the Pareto front 2. More consistent results across runs 3. Reference-point approach is more principled</p>"},{"location":"user-guide/nsga2/#further-reading","title":"Further Reading","text":"<ul> <li>Original NSGA-III paper: Deb &amp; Jain (2014) - \"An Evolutionary Many-Objective Optimization Algorithm Using Reference-Point-Based Nondominated Sorting Approach\"</li> <li>Original NSGA-II paper: Deb et al. (2002)</li> <li>pymoo documentation: https://pymoo.org/</li> <li>Das-Dennis reference directions: Das &amp; Dennis (1998)</li> </ul>"},{"location":"user-guide/perturbations/","title":"Perturbation Strategies","text":""},{"location":"user-guide/perturbations/#overview","title":"Overview","text":"<p>Adversarial perturbations are small, carefully crafted modifications to LiDAR point clouds that degrade SLAM performance while remaining imperceptible. This document describes the different perturbation strategies implemented and their effectiveness against MOLA SLAM.</p> <p>The perturbation generator implements state-of-the-art adversarial techniques based on recent research:</p> <ul> <li>FLAT: Flux-Aware Imperceptible Adversarial Attacks (ECCV 2024)</li> <li>SLACK: Attacking LiDAR-based SLAM (arXiv 2024)</li> <li>ICP Attack: Adversarial attacks on ICP registration (arXiv 2403.05666)</li> <li>ASP: Attribution-based Scanline Perturbation (IEEE 2024)</li> </ul>"},{"location":"user-guide/perturbations/#attack-objectives","title":"Attack Objectives","text":"<p>An effective adversarial perturbation must balance two goals:</p> <ol> <li>Maximize localization error - Cause MOLA to produce inaccurate trajectory estimates</li> <li>Minimize detectability - Keep perturbations small enough to avoid detection</li> </ol> <p>The NSGA-II optimization finds perturbations that achieve the best trade-off between these objectives.</p>"},{"location":"user-guide/perturbations/#perturbation-types","title":"Perturbation Types","text":""},{"location":"user-guide/perturbations/#1-dropout-attack","title":"1. Dropout Attack","text":"<p>The dropout attack removes a percentage of points from each point cloud frame.</p> <p>How it works: - Randomly select N% of points in each frame - Remove these points from the point cloud - MOLA processes the remaining points</p> <p>Parameters: - Dropout rate: 0-100% (typically 5-20%)</p> <p>Effectiveness: - Most efficient attack strategy - 18.9% ATE increase per cm of perturbation budget - At 5% dropout: achieves 120cm ATE vs 68cm baseline</p> <p>Why it works: Dropout breaks SLAM in multiple ways: - Reduces number of feature correspondences between frames - Degrades loop closure detection (fewer points to match) - Increases uncertainty in ICP alignment - Causes accumulated odometry drift</p> <p>Removing points is particularly effective because SLAM systems rely on dense, consistent measurements. Missing data creates ambiguity that propagates through the entire mapping process.</p> <p>Example: <pre><code>Original frame: 50,000 points\n5% dropout: 47,500 points (2,500 removed)\n10% dropout: 45,000 points (5,000 removed)\n</code></pre></p>"},{"location":"user-guide/perturbations/#2-gaussian-noise-attack","title":"2. Gaussian Noise Attack","text":"<p>The Gaussian noise attack adds random displacement to point coordinates.</p> <p>How it works: - For each point (x, y, z), add random noise: (x + Nx, y + Ny, z + Nz) - Noise is sampled from Gaussian distribution N(0, \u03c3\u00b2) - Standard deviation \u03c3 controls noise magnitude</p> <p>Parameters: - Standard deviation \u03c3: 0-10cm (typically 1-5cm)</p> <p>Effectiveness: - Second most efficient strategy - 15.2% ATE increase per cm of perturbation budget - At \u03c3=3cm: achieves 105cm ATE vs 68cm baseline</p> <p>Why it works: Noise degrades SLAM by: - Reducing precision of feature matching - Introducing errors in ICP point-to-plane alignment - Creating inconsistencies between overlapping scans - Degrading loop closure reliability</p> <p>Unlike dropout, noise preserves point density but corrupts position accuracy. This is particularly effective against ICP-based odometry, which assumes point measurements are accurate.</p> <p>Example: <pre><code># Add Gaussian noise with \u03c3=2cm\nnoise = np.random.normal(0, 0.02, size=points.shape)\nperturbed_points = points + noise\n</code></pre></p>"},{"location":"user-guide/perturbations/#3-feature-targeting-attack","title":"3. Feature Targeting Attack","text":"<p>The feature targeting attack identifies and perturbs high-gradient regions (edges, corners) that SLAM systems rely on for feature matching.</p> <p>How it works: 1. Compute local point density or gradient for each point 2. Identify high-gradient points (features) 3. Apply larger perturbations to these feature points 4. Apply smaller perturbations to flat regions</p> <p>Parameters: - Feature threshold: Points above this gradient are considered features - Feature perturbation: 5-15cm displacement - Background perturbation: 1-3cm displacement</p> <p>Effectiveness: - Third most efficient strategy - 12.7% ATE increase per cm of perturbation budget - More targeted than uniform noise</p> <p>Why it works: SLAM systems extract features (edges, corners, planes) for matching and alignment. By corrupting these features specifically, the attack: - Prevents correct feature correspondence - Degrades place recognition for loop closure - Increases ICP alignment errors - Creates false matches that corrupt the map</p> <p>This strategy is more sophisticated than uniform noise because it focuses perturbation budget on the most critical points for SLAM.</p> <p>Example: <pre><code># Identify features by local density\ndensity = compute_local_density(points, radius=0.5)\nis_feature = density &gt; threshold\n\n# Apply larger perturbations to features\nperturbations = np.where(is_feature[:, None],\n                         large_noise,\n                         small_noise)\nperturbed_points = points + perturbations\n</code></pre></p>"},{"location":"user-guide/perturbations/#4-ghost-points-attack","title":"4. Ghost Points Attack","text":"<p>The ghost points attack adds false points that don't correspond to real objects.</p> <p>How it works: - Generate synthetic points near real sensor readings - Add these points to the point cloud - MOLA processes both real and fake points</p> <p>Parameters: - Number of ghost points: 100-5000 per frame - Ghost point distribution: Near real points or in empty space</p> <p>Effectiveness: - Least efficient strategy - 8.3% ATE increase per cm of perturbation budget - Requires more perturbation budget for same ATE</p> <p>Why it works: Ghost points confuse SLAM by: - Creating false surfaces and structures - Introducing spurious feature matches - Degrading scan matching quality - Corrupting map consistency</p> <p>However, this is less efficient than dropout because: - SLAM systems have outlier rejection mechanisms - Ghost points in empty space are easily filtered - Adding points is more detectable than removing or shifting them</p> <p>Example: <pre><code># Add ghost points near real points\nn_ghosts = 1000\nbase_indices = np.random.choice(len(points), n_ghosts)\nghost_offset = np.random.normal(0, 0.05, size=(n_ghosts, 3))\nghost_points = points[base_indices] + ghost_offset\nperturbed_cloud = np.vstack([points, ghost_points])\n</code></pre></p>"},{"location":"user-guide/perturbations/#comparative-analysis","title":"Comparative Analysis","text":"<p>Based on experimental results:</p> Strategy ATE/cm Efficiency Best Use Case Detectability Dropout (5%) 18.9% Most efficient general attack Low (missing data is common) Gaussian noise 15.2% When dropout is detectable Medium (depends on \u03c3) Feature targeting 12.7% Targeted attack on features Medium-High Ghost points 8.3% When modifying points is detectable High (easier to detect additions)"},{"location":"user-guide/perturbations/#key-insights","title":"Key Insights","text":"<ol> <li> <p>Dropout is most efficient: Removing points causes more damage per unit of perturbation than any other strategy. This is because SLAM fundamentally relies on having complete, dense measurements.</p> </li> <li> <p>Loop closure is the weak point: All effective attacks degrade loop closure detection. Without successful loop closures, odometry drift accumulates linearly over time.</p> </li> <li> <p>Feature-based attacks are less efficient: While intuitively appealing, targeting features specifically is less efficient than uniform dropout or noise. This suggests MOLA's robustness mechanisms handle feature corruption better than missing data.</p> </li> <li> <p>Additions are easier to defend against: Ghost points are the least efficient attack, likely because MOLA has outlier rejection that filters spurious measurements.</p> </li> </ol>"},{"location":"user-guide/perturbations/#temporal-patterns","title":"Temporal Patterns","text":"<p>Perturbations can be applied with different temporal patterns:</p>"},{"location":"user-guide/perturbations/#uniform-perturbation","title":"Uniform Perturbation","text":"<p>Apply same perturbation to all frames. - Simple to implement - Consistent effect throughout trajectory - Easy to optimize</p>"},{"location":"user-guide/perturbations/#temporal-dropout","title":"Temporal Dropout","text":"<p>Apply perturbations only to specific frames. - Target loop closure frames specifically - Minimize overall perturbation budget - More sophisticated attack</p>"},{"location":"user-guide/perturbations/#adaptive-perturbation","title":"Adaptive Perturbation","text":"<p>Adjust perturbation based on MOLA's state. - Increase perturbation when MOLA is uncertain - Reduce perturbation when MOLA is confident - Requires online feedback (not implemented)</p>"},{"location":"user-guide/perturbations/#physical-constraints","title":"Physical Constraints","text":"<p>To maintain realism, perturbations are constrained:</p> <ol> <li>Maximum displacement: 50cm per point</li> <li>Larger displacements create obvious artifacts</li> <li> <p>Real sensor noise is typically &lt; 5cm</p> </li> <li> <p>Dropout rate: 0-100%</p> </li> <li>Cannot remove more than all points</li> <li> <p>Typical rates: 5-20%</p> </li> <li> <p>Noise standard deviation: 0-10cm</p> </li> <li>Based on realistic sensor noise characteristics</li> <li> <p>LiDAR accuracy is typically 1-3cm</p> </li> <li> <p>Ghost point density: &lt; 10% of real points</p> </li> <li>Too many ghost points are obviously fake</li> <li> <p>Must match real point cloud density</p> </li> <li> <p>Spatial coherence: Perturbations should be locally consistent</p> </li> <li>Random per-point perturbations create speckle noise</li> <li>Spatially correlated noise is more realistic</li> </ol>"},{"location":"user-guide/perturbations/#implementation-details","title":"Implementation Details","text":"<p>Perturbations are applied during NSGA-II fitness evaluation:</p> <ol> <li>Load original point cloud frames</li> <li>Decode genome to perturbation parameters</li> <li>Apply perturbation to each frame</li> <li>Write perturbed frames to temporary file</li> <li>Run MOLA SLAM on perturbed data</li> <li>Evaluate ATE and perturbation magnitude</li> <li>Return fitness values to NSGA-II</li> </ol> <p>The perturbation module is in src/perturbations/.</p>"},{"location":"user-guide/perturbations/#dropout-implementation","title":"Dropout Implementation","text":"<pre><code>def apply_dropout(cloud, dropout_rate):\n    \"\"\"Remove random points from cloud.\"\"\"\n    n_points = len(cloud)\n    n_keep = int(n_points * (1 - dropout_rate))\n    keep_indices = np.random.choice(n_points, n_keep, replace=False)\n    return cloud[keep_indices]\n</code></pre>"},{"location":"user-guide/perturbations/#gaussian-noise-implementation","title":"Gaussian Noise Implementation","text":"<pre><code>def apply_gaussian_noise(cloud, sigma):\n    \"\"\"Add Gaussian noise to point coordinates.\"\"\"\n    noise = np.random.normal(0, sigma, size=cloud.shape)\n    return cloud + noise\n</code></pre>"},{"location":"user-guide/perturbations/#defending-against-perturbations","title":"Defending Against Perturbations","text":"<p>Understanding these attacks informs defense strategies:</p> <ol> <li>Outlier rejection: Filter points with high residuals</li> <li>Helps against ghost points</li> <li> <p>Less effective against dropout and noise</p> </li> <li> <p>Multi-sensor fusion: Combine LiDAR with camera or IMU</p> </li> <li>Provides redundancy against single-sensor attacks</li> <li> <p>Increases attack complexity</p> </li> <li> <p>Temporal consistency: Check for frame-to-frame consistency</p> </li> <li>Detects sudden dropout or noise changes</li> <li> <p>Requires buffering multiple frames</p> </li> <li> <p>Learned anomaly detection: Train classifier to detect adversarial perturbations</p> </li> <li>Can detect statistical anomalies</li> <li> <p>Requires representative training data</p> </li> <li> <p>Robust estimation: Use RANSAC or M-estimators</p> </li> <li>Already implemented in MOLA</li> <li>Provides some inherent robustness</li> </ol>"},{"location":"user-guide/perturbations/#advanced-attack-strategies-new","title":"Advanced Attack Strategies (NEW)","text":"<p>The following advanced attacks are inspired by recent research and implemented in the 17-parameter genome:</p>"},{"location":"user-guide/perturbations/#5-edge-attack-slack-inspired","title":"5. Edge Attack (SLACK-inspired)","text":"<p>The edge attack targets edges and corners that are critical for ICP matching.</p> <p>How it works: 1. Detect edge and corner points using eigenvalue analysis 2. Classify points: planar (\u03bb1 \u2248 \u03bb2 &gt;&gt; \u03bb3), edge (\u03bb1 &gt;&gt; \u03bb2 \u2248 \u03bb3), corner (\u03bb1 \u2248 \u03bb2 \u2248 \u03bb3) 3. Shift edge points perpendicular to their principal direction 4. Maximum confusion for ICP correspondence matching</p> <p>Parameters: - Edge attack strength: 0-100% - Max edge shift: 8cm</p> <p>Why it works: - \"Location of injection matters more than quantity\" (SLACK paper) - Edge/corner points are critical for ICP - perturbing them has disproportionate impact - Shifts perpendicular to principal direction maximize alignment confusion</p>"},{"location":"user-guide/perturbations/#6-temporal-drift-attack-icp-attack-inspired","title":"6. Temporal Drift Attack (ICP Attack-inspired)","text":"<p>The temporal drift attack applies accumulating bias across frames.</p> <p>How it works: 1. Accumulate drift in a specified direction over time 2. Apply drift with decay (0.98) to prevent explosion 3. Each frame adds to accumulated drift 4. Prevents SLAM from recognizing previously visited locations</p> <p>Parameters: - Temporal drift strength: 0-100% - Max drift per frame: 5cm - Drift direction: Encoded in genome</p> <p>Why it works: - Consistent bias accumulates over trajectory - Breaks loop closure detection (devastating effect) - SLAM cannot correct accumulated odometry drift</p>"},{"location":"user-guide/perturbations/#7-scanline-perturbation-asp-inspired","title":"7. Scanline Perturbation (ASP-inspired)","text":"<p>The scanline attack perturbs points along their laser beam directions.</p> <p>How it works: 1. Compute range direction for each point (sensor at origin) 2. Apply perturbation along scanline direction 3. Mix random (3cm std) and systematic (wave pattern) components 4. Physically realistic - simulates particles between sensor and objects</p> <p>Parameters: - Scanline strength: 0-100%</p> <p>Why it works: - Simulates realistic sensor interference (dust, particles) - Hard to detect as it follows natural sensor noise patterns - Affects range measurements systematically</p>"},{"location":"user-guide/perturbations/#8-strategic-ghost-points-slack-inspired","title":"8. Strategic Ghost Points (SLACK-inspired)","text":"<p>Strategic placement of ghost points near geometric features.</p> <p>How it works: 1. Detect edges and high-curvature regions 2. Select high-feature points as bases (top 30%) 3. Add ghost points with small offsets (2.5cm std) 4. Ghost points are close enough to real features to confuse ICP</p> <p>Parameters: - Strategic ghost: 0-100% - Activates when &gt; 50%</p> <p>Why it works: - Ghost points placed near features create ambiguous correspondences - ICP cannot distinguish real features from nearby ghosts - More effective than random ghost placement</p>"},{"location":"user-guide/perturbations/#9-geometric-distortion-key-for-icp","title":"9. Geometric Distortion (KEY for ICP)","text":"<p>Systematic geometric distortion to break ICP convergence.</p> <p>How it works: 1. Apply range-dependent scaling 2. ICP is robust to random noise but weak against systematic distortions 3. Scaling, shearing, or range-dependent bias</p> <p>Parameters: - Geometric distortion strength: 0-100%</p> <p>Why it works: - ICP assumes point-to-point correspondence - Systematic distortions violate ICP assumptions - Breaks convergence to correct alignment</p>"},{"location":"user-guide/perturbations/#future-directions","title":"Future Directions","text":"<p>Potential improvements to perturbation strategies:</p> <ol> <li>Transfer attacks: Optimize on one SLAM system, test on others</li> <li>Physical perturbations: 3D-print adversarial objects to place in environment</li> <li>Online adaptive attacks: Adjust perturbations based on SLAM state feedback</li> <li>Semantic targeting: Perturb specific object types (walls, obstacles)</li> </ol>"},{"location":"user-guide/perturbations/#keyframes-vs-all-frames","title":"Keyframes vs All Frames","text":"<p>An important consideration is whether to perturb all frames or only keyframes:</p> <p>All frames (113 frames at 10Hz): - LiDAR publishes at 10Hz during ~11.3 second trajectory - More data to perturb - Affects odometry estimation</p> <p>Keyframes only (49 frames): - MOLA selects keyframes when robot moves enough - Less data to perturb - Directly affects what MOLA processes - More efficient use of perturbation budget</p> <p>Current implementation perturbs all frames, but future work could target keyframes specifically.</p>"},{"location":"user-guide/perturbations/#summary","title":"Summary","text":"<ul> <li>Dropout is the most efficient attack (18.9% ATE/cm)</li> <li>Loop closure degradation is the primary damage mechanism</li> <li>Physical constraints ensure perturbations remain realistic</li> <li>Different attacks have different detectability vs effectiveness trade-offs</li> <li>NSGA-II optimization discovers these trade-offs automatically</li> </ul> <p>The optimization process reveals that simpler attacks (dropout) are more effective than complex ones (feature targeting), which is a valuable insight for both adversarial robustness and SLAM system design.</p>"}]}